{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b570b-cb7e-4afa-82e5-6198940c3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import set_config\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27475ee-b564-4c13-a919-a3afc78d5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_file_path = \"/kaggle/input/home-data-for-ml-course/train.csv\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "random_state = 0\n",
    "missing_columns_drop_threshold = 0.5\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a5088-6b22-4111-b27c-31e15986a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique data types of every column\n",
    "print(\"Unique data types:\")\n",
    "print([str(x) for x in np.unique(df.dtypes.values)])\n",
    "\n",
    "# Dataframe of all numeric types\n",
    "df_num = df.select_dtypes(include=[\"number\"])\n",
    "\n",
    "# Dataframe of non-numerics\n",
    "df_obj = df.select_dtypes(exclude=[\"number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0570321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cf469-b202-428e-a3b7-8c8b89d6bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View null counts and data type per column\n",
    "def get_df_info(df, missing_only=False):\n",
    "    \"\"\"\n",
    "    Function to get information about the dataframe\n",
    "    :param df: DataFrame\n",
    "    :return: DataFrame with column names, non-null counts, and data types\n",
    "    \"\"\"\n",
    "    ret = pd.DataFrame({\n",
    "        \"column\": df.columns,\n",
    "        \"non_null_count\": df.notnull().sum(),\n",
    "        \"pct_missing\": df.isnull().sum() / df.shape[0],\n",
    "        \"data_type\": df.dtypes\n",
    "    }).reset_index(drop=True).sort_values(by=[\"non_null_count\"])\n",
    "    if missing_only:\n",
    "        return ret[ret[\"non_null_count\"] < df.shape[0]]\n",
    "    return ret\n",
    "\n",
    "print(get_df_info(df, missing_only=True).to_string())\n",
    "\n",
    "# # View data type and counts of nulls\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea30aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of rows with missing values\n",
    "def get_rows_missing(df):\n",
    "    \"\"\"\n",
    "    Function to get the number of rows with missing values\n",
    "    :param df: DataFrame\n",
    "    :return: Series with counts of missing values per row\n",
    "    \"\"\"\n",
    "    return df.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "print(get_rows_missing(df).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa02929-cfa2-46df-83f1-3065636044af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and features\n",
    "target = \"SalePrice\"\n",
    "y = df[\"SalePrice\"]\n",
    "\n",
    "# Create X\n",
    "features = list(set(df.columns) - set(target))\n",
    "\n",
    "# Select columns corresponding to features, and preview the data\n",
    "X = df[features]\n",
    "\n",
    "numerical_features = [\"LotFrontage\",\"LotArea\",\"YearBuilt\",\"YearRemodAdd\",\"MasVnrArea\",\"BsmtFinSF1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"LowQualFinSF\",\"GrLivArea\",\"BsmtFullBath\",\"BsmtHalfBath\",\"FullBath\",\"HalfBath\",\"Bedroom\",\"Kitchen\",\"TotRmsAbvGrd\",\"Fireplaces\",\"GarageYrBlt\",\"GarageCars\",\"GarageArea\",\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"3SsnPorch\",\"ScreenPorch\",\"PoolArea\",\"MiscVal\",\"MoSold\",\"YrSold\"]\n",
    "categorical_features = list(set(features) - set(numerical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde62cfc-d354-4a33-9216-899f8eec8128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=random_state)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f075cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "def drop_columns_with_missing_values(df: pd.DataFrame, threshold=None, fit=False):\n",
    "    \"\"\"\n",
    "    Function to drop columns with missing values above a certain threshold\n",
    "    :param df: DataFrame\n",
    "    :param threshold: float, percentage of missing values to drop the column\n",
    "    :return: DataFrame with columns dropped\n",
    "    \"\"\"\n",
    "    df_info = get_df_info(df=df)\n",
    "    # print(df_info.loc[df_info[\"pct_missing\"] >= 0.5, \"column\"])\n",
    "    if threshold is None:\n",
    "        dropped_columns = df_info.loc[df_info[\"pct_missing\"] > 0, \"column\"].tolist()\n",
    "    else:\n",
    "        dropped_columns = df_info.loc[df_info[\"pct_missing\"] >= threshold, \"column\"].tolist()\n",
    "\n",
    "    if fit:\n",
    "        drop_columns_with_missing_values.dropped_columns = dropped_columns\n",
    "    return df.drop(columns=dropped_columns)\n",
    "\n",
    "def impute_fill(df: pd.DataFrame):\n",
    "    imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "    impute_fill.imputer = imputer\n",
    "    return imputer.fit_transform(df)\n",
    "\n",
    "def encode_ordinal(df: pd.DataFrame, fit: bool = False, categorical_features=None):\n",
    "    # Safeguard\n",
    "    categorical_features = set(df.columns).intersection(set(categorical_features))\n",
    "\n",
    "    # Exclude already-encoded columns\n",
    "    categorical_features = df[categorical_features].select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "    df = df.copy()\n",
    "    df[categorical_features] = df[categorical_features].astype(str)\n",
    "    if fit:\n",
    "        encoder = OrdinalEncoder()\n",
    "        ct = ColumnTransformer(transformers=[(\"encoder\", encoder, categorical_features)], remainder=\"passthrough\")\n",
    "        ct.fit(df)\n",
    "        encode_ordinal.encoder = ct\n",
    "    return ct.transform(df)\n",
    "\n",
    "def preproc(df: pd.DataFrame, fit: bool = False):\n",
    "    # Constants\n",
    "    imputer = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "    preproc_funcs = [\n",
    "        # Drop columns with more missing values than missing_columns_drop_threshold\n",
    "        (partial(drop_columns_with_missing_values, threshold=missing_columns_drop_threshold, fit=fit),\n",
    "            partial(drop_columns_with_missing_values, threshold=missing_columns_drop_threshold)),\n",
    "\n",
    "        # Impute missing values\n",
    "        (impute_fill, impute_fill),\n",
    "\n",
    "        # Encode categorical features\n",
    "        (partial(encode_ordinal, categorical_features=categorical_features, fit=fit),\n",
    "            partial(encode_ordinal, categorical_features=categorical_features)),\n",
    "    ]\n",
    "    if fit:\n",
    "        preproc_funcs = [f[0] for f in preproc_funcs]\n",
    "    else:\n",
    "        preproc_funcs = [f[1] for f in preproc_funcs]\n",
    "\n",
    "    for f in preproc_funcs:\n",
    "        df = f(df)\n",
    "    return df\n",
    "\n",
    "X_train_preproc = preproc(X_train, fit=True)\n",
    "X_train_preproc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb311da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization/normalization\n",
    "scale_columns = numerical_features\n",
    "scaler = StandardScaler().fit(X_train_preproc[scale_columns])\n",
    "# scaler = MinMaxScaler().fit(X_train_preproc[scale_columns])\n",
    "X_train_preproc[scale_columns] = scaler.transform(X_train_preproc[scale_columns])\n",
    "X_train_preproc.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70821c12-7575-4ed1-beb0-58af0213c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition and training\n",
    "mdl = RandomForestRegressor(random_state=random_state)\n",
    "mdl.fit(X_train_preproc, y_train)\n",
    "for f in preproc_funcs:\n",
    "    print(f[0])\n",
    "    print(f[1])\n",
    "#     X_val = f[1](X_val)\n",
    "# X_val.shape\n",
    "# mae = mean_absolute_error(y_val, mdl.predict(X_val))\n",
    "# print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c58e7-eb76-430d-ac27-c6a3cc3c126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "maes = []\n",
    "n_trees_search = (2 ** np.arange(15))\n",
    "for n_trees in n_trees_search:\n",
    "    print(f\"Training for n_trees = {n_trees}\")\n",
    "    mdl = RandomForestRegressor(n_estimators=n_trees, random_state=random_state)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    mae = mean_absolute_error(y_val, mdl.predict(X_val))\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57a643-5736-4811-9f1c-126f1e886fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter selection\n",
    "for n, mae in enumerate(maes):\n",
    "    print(f\"n_tree = {n_trees_search[n]}, mae = {mae}\")\n",
    "mae_min = min(maes)\n",
    "n_trees = n_trees_search[maes.index(mae_min)]\n",
    "print(f\"best = {n_trees}, mae = {mae_min}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444563eb-d6f8-461d-aefe-db7d5f1cc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining with best hyperparameter, and using the validation set as well\n",
    "X_train2 = pd.concat((X_train, X_val))\n",
    "y_train2 = pd.concat((y_train, y_val))\n",
    "mdl = RandomForestRegressor(n_estimators=n_trees, random_state=random_state)\n",
    "mdl.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6cfb9-42b2-48aa-af7b-618f8d56bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate accuracy on data set not used for training\n",
    "mae = mean_absolute_error(y_test, mdl.predict(X_test))\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e936fc3-c5bb-42b9-9a80-8ed9e1764917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on all data to prepare for submission\n",
    "mdl.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1037f01-4fa2-4e12-a775-c35c5210b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and fit\n",
    "test_data = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\n",
    "X_test = test_data[features]\n",
    "test_preds = mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b49fa-c6c1-4413-9c55-01d81d06be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Id\": test_data.Id, \"SalePrice\": test_preds})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
