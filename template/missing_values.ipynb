{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ae3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a52f56-3419-4071-af2d-eebf2a807b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Constants\n",
    "data_file_path = \"./data/home-data-for-ml-course/train.csv\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "random_state = 0\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Target and features\n",
    "y = df.SalePrice\n",
    "\n",
    "# All numeric without missing values\n",
    "features_no_missing = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "features = features_no_missing + ['LotFrontage','MasVnrArea','GarageYrBlt'] # numeric types with missing columns\n",
    "X = df[features]\n",
    "\n",
    "# Splitting\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=val_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbd81e-7ada-4230-ba2b-2168ba6d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing values per column\n",
    "missing_value_count_by_column = train_X.isnull().sum()\n",
    "columns_with_missing_values = missing_value_count_by_column[missing_value_count_by_column > 0]\n",
    "print(train_X.shape)\n",
    "print(columns_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27931abb-6421-421f-8a65-f299deb926c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# Option 1: Drop columns with missing values. Not so great if the column to be dropped has a lot of data.\n",
    "missing_handled_train_X = train_X.drop(columns_with_missing_values.index, axis=1)\n",
    "missing_handled_valid_X = val_X.drop(columns_with_missing_values.index, axis=1)\n",
    "\n",
    "# Note the difference in columns\n",
    "print(train_X.columns)\n",
    "print(missing_handled_train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d52741-e520-4c2d-b6f2-051412810eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: If not dropping the column, it's possible to replace missing values with the mean of that column.\n",
    "# Other methods exist such as filling in with 0 or with the mode.\n",
    "from sklearn.impute import SimpleImputer\n",
    "my_imputer = SimpleImputer()\n",
    "mean_imputed_train_X = pd.DataFrame(my_imputer.fit_transform(train_X), columns=train_X.columns)\n",
    "mean_imputed_val_X = pd.DataFrame(my_imputer.transform(val_X), columns=val_X.columns)\n",
    "\n",
    "# Note the difference in row counts of missing values\n",
    "print(\"Number of rows in original data: \" +\n",
    "      str(train_X.shape[0]))\n",
    "print(\"Number of rows with missing entries in original data: \"\n",
    "      + str(train_X[columns_with_missing_values.index].isnull().any(axis=1).sum()))\n",
    "print(\"Number of rows in imputed data: \" +\n",
    "      str(mean_imputed_train_X.shape[0]))\n",
    "print(\"Number of rows with missing entries in inputed data: \"\n",
    "      + str(mean_imputed_train_X[columns_with_missing_values.index].isnull().any(axis=1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a986016-7e36-4c27-8a8b-364b127a1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Impute data while keeping track of entries that were imputed by creating a new column.\n",
    "def track_missing_entries_and_impute(dfin):\n",
    "    dfin = dfin.copy()\n",
    "    for column in columns_with_missing_values.index:\n",
    "        dfin[column + \"_missing\"] = dfin[column].isnull()\n",
    "    return dfin\n",
    "\n",
    "tracked_missing_train_X = track_missing_entries_and_impute(train_X)\n",
    "tracked_missing_val_X = track_missing_entries_and_impute(val_X)\n",
    "my_imputer = SimpleImputer()\n",
    "imputed_tracked_missing_train_X = pd.DataFrame(my_imputer.fit_transform(tracked_missing_train_X), columns=tracked_missing_train_X.columns)\n",
    "imputed_tracked_missing_val_X = pd.DataFrame(my_imputer.transform(tracked_missing_val_X), columns=tracked_missing_val_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febd532-cefb-4124-8f27-07b562e5f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different methods of handling missing values by computing MAE\n",
    "def score(train_X, val_X, train_y, val_y):\n",
    "    mdl = RandomForestRegressor(random_state=random_state)\n",
    "    mdl.fit(train_X, train_y)\n",
    "    mae = mean_absolute_error(val_y, mdl.predict(val_X))\n",
    "    return (mae, mdl)\n",
    "\n",
    "mae_regular, _ = score(train_X, val_X, train_y, val_y)\n",
    "mae_imputed, _ = score(mean_imputed_train_X, mean_imputed_val_X, train_y, val_y)\n",
    "mae_missing_tracked, _ = score(imputed_tracked_missing_train_X, imputed_tracked_missing_val_X, train_y, val_y)\n",
    "print(f\"mae_regular = {mae_regular}\")\n",
    "print(f\"mae_imputed = {mae_imputed}\")\n",
    "print(f\"mae_missing_tracked = {mae_missing_tracked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to the above, other options include:\n",
    "# 1. Impute using the mean/median/mode\n",
    "# 2. Replace with a constant value\n",
    "# 3. Replace with the mean/media/mode of a subgroup by using groupby\n",
    "# 4. Use a machine learning model to predict the missing values\n",
    "# 5. Use knn to impute the missing values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
