{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "da448159-0f11-4b37-a4ee-bf5d76b84fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Constants\n",
    "data_file_path = \"./data/home-data-for-ml-course/train.csv\"\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "random_state = 0\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Target and features\n",
    "y = df.SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a87122c-7a19-41da-9257-c1e5b059d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "X = df.drop(labels=[\"SalePrice\"], axis=1)\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=val_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d358b0bd-df84-4a2a-a583-7fb7fbedb518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0       RL   Pave   NaN      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1       RL   Pave   NaN      Reg         Lvl    AllPub       FR2       Gtl   \n",
       "2       RL   Pave   NaN      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "3       RL   Pave   NaN      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "4       RL   Pave   NaN      IR1         Lvl    AllPub       FR2       Gtl   \n",
       "\n",
       "  Neighborhood Condition1  ... GarageType GarageFinish GarageQual GarageCond  \\\n",
       "0      CollgCr       Norm  ...     Attchd          RFn         TA         TA   \n",
       "1      Veenker      Feedr  ...     Attchd          RFn         TA         TA   \n",
       "2      CollgCr       Norm  ...     Attchd          RFn         TA         TA   \n",
       "3      Crawfor       Norm  ...     Detchd          Unf         TA         TA   \n",
       "4      NoRidge       Norm  ...     Attchd          RFn         TA         TA   \n",
       "\n",
       "  PavedDrive PoolQC Fence MiscFeature SaleType SaleCondition  \n",
       "0          Y    NaN   NaN         NaN       WD        Normal  \n",
       "1          Y    NaN   NaN         NaN       WD        Normal  \n",
       "2          Y    NaN   NaN         NaN       WD        Normal  \n",
       "3          Y    NaN   NaN         NaN       WD       Abnorml  \n",
       "4          Y    NaN   NaN         NaN       WD        Normal  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find non-numeric columns\n",
    "is_obj = X.dtypes == \"object\"\n",
    "obj_cols = list(is_obj[is_obj].index)\n",
    "X[obj_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "78bd0827-987e-4825-966e-64600aa1dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Drop columns with categorical values. Not great if the column is useful.\n",
    "dropped_train_X = train_X.drop(labels=obj_cols, axis=1)\n",
    "dropped_val_X = val_X.drop(labels=obj_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "514848cc-3c2f-481a-becf-f87490851a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Ordinal encoding\n",
    "# Not great if the column is a nominal variable. The values of a nominal variable have no inherent order.\n",
    "\n",
    "# A situation can arise such that some values of the categorical column appear in the validation set\n",
    "# but do not appear in the training set. Ordinal encoding would then fail. A solution to this is to drop\n",
    "# the columns that have values that appear in the validation set but not in the training set.\n",
    "good_obj_cols = [obj_col for obj_col in obj_cols if set(val_X[obj_col]).issubset(set(train_X[obj_col]))]\n",
    "bad_obj_cols = list(set(obj_cols) - set(good_obj_cols))\n",
    "\n",
    "# Drop the bad columns\n",
    "oe_train_X = train_X.drop(labels=bad_obj_cols, axis=1)\n",
    "oe_val_X = val_X.drop(labels=bad_obj_cols, axis=1)\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "oe_train_X[good_obj_cols] = oe.fit_transform(oe_train_X[good_obj_cols])\n",
    "oe_val_X[good_obj_cols] = oe.transform(val_X[good_obj_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b545225d-9f93-496b-a952-919c499fe7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: One-hot encoding creates a boolean column for every unique value of categorical column. The value\n",
    "# of the new boolean column indicates whether that sample had that value unique value of the categorical column.\n",
    "# The advantage of one-hot encoding over ordinal encoding is that it does not assume an order between the unique\n",
    "# values of a categorical column.\n",
    "\n",
    "# However, much like ordinal encoding, some values of a categorical column can appear in the validation set but\n",
    "# not in the training set. This is handled by setting the optional argument handle_unknown=\"ignore\" when\n",
    "# instantiating OneHotEncoder.\n",
    "\n",
    "# A drawback of one-hot encoding is that it can introduce a lot of new entries and columns. By adding these new\n",
    "# columns, it introduces a lot of extra dimensions, which isn't ideal. See Curse of Dimensionality.\n",
    "# One way to handle this is to only include columns that have low cardinality (less than 10 unique values). A\n",
    "# rule of thumb is to avoid one-hot encoding if a column has more than 15 unique values.\n",
    "obj_cols_unq_cnt = train_X[obj_cols].nunique()\n",
    "low_card_cols = list(obj_cols_unq_cnt[obj_cols_unq_cnt <= 10].index)\n",
    "high_card_cols = list(set(obj_cols) - set(low_card_cols))\n",
    "\n",
    "# Drop high cardinality columns\n",
    "oh_train_X = train_X.drop(labels=high_card_cols, axis=1)\n",
    "oh_val_X = val_X.drop(labels=high_card_cols, axis=1)\n",
    "\n",
    "# One-hot encode low cardinality columns. Remember there are still other numeric columns.\n",
    "# sparse_output=\"False\" returns a non-sparse numpy array.\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "oh_train_cols = ohe.fit_transform(oh_train_X[low_card_cols])\n",
    "oh_val_cols = ohe.transform(oh_val_X[low_card_cols])\n",
    "\n",
    "# Drop low cardinality columns because they will be replaced\n",
    "oh_train_X = oh_train_X.drop(labels=low_card_cols, axis=1)\n",
    "oh_val_X = oh_val_X.drop(labels=low_card_cols,axis=1)\n",
    "\n",
    "# Get column names of new one-hot encoded columns\n",
    "oh_col_names = ohe.get_feature_names_out()\n",
    "\n",
    "# Create DataFrames of one-hot encoded columns\n",
    "oh_train_cols = pd.DataFrame(data=oh_train_cols, columns=oh_col_names, index=oh_train_X.index)\n",
    "oh_val_cols = pd.DataFrame(data=oh_val_cols, columns=oh_col_names, index=oh_val_X.index)\n",
    "\n",
    "# Create final DataFrames by concatenation\n",
    "oh_train_X = pd.concat([oh_train_X, oh_train_cols], axis=1)\n",
    "oh_val_X = pd.concat([oh_val_X, oh_val_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5708d738-816c-41b4-833f-e275840f22e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "50bb5e0c-3022-48a8-951c-92990dd155a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped_mae = 17640.981538461536\n",
      "oe_mae = 17065.055598290597\n",
      "oh_mae = 17067.91175213675\n"
     ]
    }
   ],
   "source": [
    "dropped_mae = score_dataset(dropped_train_X, dropped_val_X, train_y, val_y)\n",
    "oe_mae = score_dataset(oe_train_X, oe_val_X, train_y, val_y)\n",
    "oh_mae = score_dataset(oh_train_X, oh_val_X, train_y, val_y)\n",
    "\n",
    "print(f\"dropped_mae = {dropped_mae}\")\n",
    "print(f\"oe_mae = {oe_mae}\")\n",
    "print(f\"oh_mae = {oh_mae}\")\n",
    "\n",
    "# In this case, ordinal encoding and one-hot encoding are not all that different. A rule of thumb is\n",
    "# that one-hot encoding > ordinal encoding > dropping."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
