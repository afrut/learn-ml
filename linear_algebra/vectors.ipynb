{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8496a1b3-5f51-4af9-ac57-dff30cfc2c53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94553816-b7b5-4aa7-b0f9-1ad28cbce76b",
   "metadata": {},
   "source": [
    "A vector $x$ is a collection of numbers that defines a point relative to the origin. It can be visualized as an arrow starting from the origin and going to the point defined.\n",
    "\n",
    "This denotes that $x$ is a vector in 2D space. It denotes the point $[3, -2]$: 3 units to the right of the origin $[0, 0]$ along the x-axis, and 2 units down along the y-axis.\n",
    "\\begin{align}\n",
    "    x &\\in \\mathbb{R}^{2} \\\\\n",
    "    x &= \\begin{bmatrix} 3 \\\\ -2 \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "This next vector $y$ is a vector in 3D space. It denotes the point $[-2, 7, 5]$: 2 units to the left of the origin along the x-axis, 7 units along the positive y-axis, and 5 units up along the positive z-axis.\n",
    "\\begin{align}\n",
    "    x &\\in \\mathbb{R}^{3} \\\\\n",
    "    x &= \\begin{bmatrix} -2 \\\\ 7 \\\\ 5 \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "So any vector $x$ is a collection of numbers that define a point in $n$D space $\\mathbb{R}^{n}$.\n",
    "\n",
    "Elements of a vector $x$ are referred to by indexing. For example, $x\\left[ 2 \\right]$ refers to the 2nd element of $x$. In the 3D case, $x\\left[ 2 \\right] = 7$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a56c1-aec8-4d22-b456-4ec8ec13f50e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3d80c5-ff4d-4bd8-a8d9-93b0ef9fd910",
   "metadata": {},
   "source": [
    "Vectors are often represented as column vectors. The transpose of a column vector is simply a vector that is a row vector. This distinction becomes important when matrix multiplication is involved.\n",
    "\n",
    "\\begin{align}\n",
    "    x &= \\begin{bmatrix} -2 \\\\ 7 \\\\ 5 \\end{bmatrix} \\\\\n",
    "    x^{T} &= \\begin{bmatrix} -2 & 7 & 5 \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "The transpose of a vector is commonly used to express the [dot product](#Dot-Product) of 2 vectors as $x^{T}y$. It is also commonly used to express the sum-of-squares of a vector $x$ as $x^{T}x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f67fc-f87f-4ea5-bf0f-159c138b7ea9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Magnitude, Direction, Unit and Normal Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8145c-b8f3-4268-adcd-5c7544b387cd",
   "metadata": {},
   "source": [
    "The magnitude of the vector gives a sense of the size, or \"how big\", the vector is. The [$L^{2}$](./norms.ipynb#L2) is used to compute the magnitude of the vector.\n",
    "\n",
    "$$ \\lVert x \\rVert_{2} = \\lVert x \\rVert = \\sqrt{\\sum_{i} x_{i}^{2}} $$\n",
    "\n",
    "A unit or normal vector is a vector whose magnitude is $1$. To get such a vector, we can take any vector $x$ and divide it by its magnitude $\\lVert x \\rVert$.\n",
    "\n",
    "$$ \\hat{x} = \\frac{x}{\\lVert x \\rVert} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96edface-174d-4612-8459-c00b98dcf536",
   "metadata": {},
   "source": [
    "A vector can be thought of as 2 components: its magnitude and direction. Unit vectors are convenient when storing the direction of the vector since it only has to be multiplied or scaled by a constant to get another vector in the same direction. For example,\n",
    "\n",
    "\\begin{align}\n",
    "    x &= \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} \\\\\n",
    "    \\lVert x \\rVert &= \\sqrt{\\sum_{i} x_{i}^{2}} \\\\\n",
    "    \\lVert x \\rVert &= \\sqrt{3^{2} + 2^{2}} = \\sqrt{9 + 4} = \\sqrt{13} \\\\\n",
    "    \\hat{x} &= \\frac{x}{\\lVert x \\rVert} = \\begin{bmatrix} \\frac{3}{\\sqrt{13}} \\\\ \\frac{2}{\\sqrt{13}} \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "We can derive a vector $y$ that has a magnitude of $3$ with the same direction as $x$ by doing the following.\n",
    "$$\n",
    "    y = 3 \\hat{x} = 3 \\begin{bmatrix} \\frac{3}{\\sqrt{13}} \\\\ \\frac{2}{\\sqrt{13}} \\end{bmatrix}\n",
    "    = \\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469c5cb-65c1-4a55-8aef-e714266b2883",
   "metadata": {},
   "source": [
    "Let's compute $\\lVert y \\rVert$ to verify that $\\hat{y} = \\hat{x}$.\n",
    "\\begin{align}\n",
    "    \\hat{y} &= \\frac{y}{\\lVert y \\rVert} =\n",
    "        \\frac{\\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}}\n",
    "            {\\sqrt{\\left( \\frac{9}{\\sqrt{13}} \\right) ^{2} + \\left( \\frac{6}{\\sqrt{13}} \\right) ^{2}}}\n",
    "        = \\frac{\\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}}\n",
    "            {\\sqrt{ \\frac{81}{13} + \\frac{36}{13} }}\n",
    "        = \\frac{\\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}}\n",
    "            {\\sqrt{ \\frac{117}{13} }}\n",
    "        = \\frac{\\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}}\n",
    "            {\\sqrt{ \\frac{9 \\cdot 13}{13} }}\n",
    "        = \\frac{\\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}}\n",
    "            {\\sqrt{ 9 }}\n",
    "        = \\frac{\\begin{bmatrix} \\frac{9}{\\sqrt{13}} \\\\ \\frac{6}{\\sqrt{13}} \\end{bmatrix}}{3}\n",
    "        = \\begin{bmatrix} \\frac{3}{\\sqrt{13}} \\\\ \\frac{2}{\\sqrt{13}} \\end{bmatrix}\n",
    "        = \\hat{x}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448c1b9-bbc6-4516-9033-9fab7f0b7866",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb3b4d-b63d-4b66-854d-a1f05b861ce8",
   "metadata": {},
   "source": [
    "The span of a vector is any vector that can be computed by scaling the original vector by any constant $\\alpha$. The span $S_{x}$ of the vector $x$ is:\n",
    "\\begin{align}\n",
    "    \\alpha &\\in \\mathbb{R} \\\\\n",
    "    x &\\in \\mathbb{R}^{n} \\\\\n",
    "    S_{x} &= \\alpha x\n",
    "\\end{align}\n",
    "\n",
    "The span of a vector is simply a line that goes in both directions indefinitely. Consequently, if another vector $y$ is simply $x$ scaled by a constant ($y = \\alpha x$), then the span of $y$ is the same as the span of $x$.\n",
    "\\begin{align}\n",
    "    \\alpha, \\beta &\\in \\mathbb{R} \\\\\n",
    "    S_{y} &= \\beta y \\\\\n",
    "    y &= \\alpha x \\\\\n",
    "    S_{y} &= \\beta \\alpha x\n",
    "\\end{align}\n",
    "\n",
    "In the above, $\\beta \\alpha$ is still an arbitrary constant, so the span of y $S_{y}$ is the same as the span of x $S_{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a39731-4fa2-4417-88b3-896c21767f7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Linear Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118e7ab-f271-45fe-aa15-a4ace78e60dd",
   "metadata": {},
   "source": [
    "A linear combination $x$ of vectors $u$, $v$, and $w$ is simply the sum of the product of these vectors and some real coefficients $a$, $b$, and $c$:\n",
    "\\begin{align}\n",
    "    a, b, c &\\in \\mathbb{R} \\\\\n",
    "    u, v, w &\\in \\mathbb{R}^{n} \\\\\n",
    "    x &= au + bv + cw\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d338c-e009-4500-a836-54fa7eca9bd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Span of a Set of Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b383f-7511-4192-a9b3-8ca366e16ccf",
   "metadata": {},
   "source": [
    "The span of a set of vectors $\\left\\{ x, y \\right\\}$ is the set of all vectors $S$ that can be computed as a linear combination of $x$ and $y$.\n",
    "\\begin{align}\n",
    "    \\alpha_{i}, \\beta_{i} &\\in \\mathbb{R} \\\\\n",
    "    v_{i} &\\in \\mathbb{R}^{n} \\\\\n",
    "    S &= \\left\\{ v_{i} \\right\\} \\;\\;\\;\\; \\mathrm{s.t.} \\;\\;\\;\\; v_{i} = \\alpha_{i}x + \\beta_{i}y\n",
    "\\end{align}\n",
    "\n",
    "Intuitively, the span of a set of vectors gives a sense of how much of the vector space $R^{n}$ these vectors can cover together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fcd900-a190-4b10-a9a0-5cbf432c4b21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Basis Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e833b8-1d87-47a8-9d8e-bf6bfa27aa5c",
   "metadata": {},
   "source": [
    "There are an infinite number of 2D vectors in $\\mathbb{R}^{2}$. However, every vector can be represented by a linear combination of 2 unit directional vectors. So far, we have assumed the following basis vectors.\n",
    "\\begin{align}\n",
    "    \\alpha, \\beta &\\in \\mathbb{R} \\\\\n",
    "    x &\\in \\mathbb{R^{2}} \\\\\n",
    "    \\hat{i} &= \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\\\\n",
    "    \\hat{j} &= \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\\\\n",
    "    x &= \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}\n",
    "        = \\hat{i} \\alpha + \\hat{j} \\beta\n",
    "        = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\alpha\n",
    "            + \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\beta\n",
    "\\end{align}\n",
    "\n",
    "$\\hat{i}$ and $\\hat{j}$ form a **basis** for the vector space $V = \\mathbb{R}^{2}$. The span of the set $\\left\\{ \\hat{i}, \\hat{j} \\right\\}$ is all of $\\mathbb{R}^{2}$, since every vector in $R^{2}$ can be derived from linear combinations of $\\hat{i}$ and $\\hat{j}$. Furthermore, since $\\hat{i}$ and $\\hat{j}$ both have magnitudes of 1, the are referred to as unit basis vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af26ccc-b340-4762-88c8-aaf9647761a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Linear Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da8350d-03ae-4e3b-acd1-d861b3c103bd",
   "metadata": {},
   "source": [
    "Vectors $u$, $v$, and $w$ are linearly independent vectors if any of the vectors cannot be derived as a linear combination of the other 2. That is, no constants $a$, $b$, $c$, $d$, $e$, $f$ exists such that:\n",
    "\\begin{align}\n",
    "    w &= au + bv \\\\\n",
    "    v &= cu + dw \\\\\n",
    "    u &= ev + fw \\\\\n",
    "    a, b, c, d, e, f &\\in \\mathbb{R} \\\\\n",
    "    u, v, w &\\in \\mathbb{R}^{n} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d99e9e7-d2cb-4582-87c1-ed1c160172ce",
   "metadata": {},
   "source": [
    "# Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f55cb6-38c0-4182-bc32-4e8b23fb39ee",
   "metadata": {},
   "source": [
    "The dot product between two vectors $x$ and $y$ is the sum of the element-wise product of the two vectors.\n",
    "\n",
    "\\begin{align}\n",
    "    x \\cdot y &= x^{T}y = \\sum_{i} x_{i}y_{i} = \\lVert x \\rVert \\lVert y \\rVert \\cos{\\theta}\n",
    "\\end{align}\n",
    "\n",
    "The dot product gives a measure of how similar the directions of the two vectors are. If $x \\cdot y$ is close to $\\lVert x \\rVert \\lVert y \\rVert$, then $\\cos{\\theta}$ must be close to 1 and $\\theta$ must be close to 0.\n",
    "\n",
    "Similarly, if $x$ and $y$ are pointing in exactly opposite directions, then $\\cos{\\theta} = -1$ and the $x \\cdot y$ < 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb4ef9-ffc8-415e-974d-a46c3dfb44d2",
   "metadata": {},
   "source": [
    "# Orthogonal Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e563d5-7aaf-4a15-9ec9-555d1f4473af",
   "metadata": {},
   "source": [
    "Two vectors $x$ and $y$ are orthogonal if their dot product $x \\cdot y = 0$. This means that the two vectors form a right angle, meaning the angle between them is $90 \\degree$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a839da-6f76-45b1-be6c-407a9a32da8d",
   "metadata": {},
   "source": [
    "# Orthonormal Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796dda2-59cb-4831-a304-742b057f2b94",
   "metadata": {},
   "source": [
    "Two vectors are orthonormal if they are orthogonal and both have magnitudes of 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
